# SightOfBlind

**SightOfBlind** is a real-time assistive system designed to support blind and visually impaired individuals by enabling object-based indoor navigation using voice commands and spoken feedback. It is fully offline, wearable, and powered by edge AI using a Raspberry Pi 5 and YOLOv11 object detection.

---

## ğŸ¯ Project Overview

Visually impaired individuals face constant challenges in navigating unfamiliar environments. SightOfBlind aims to restore autonomy by allowing users to say commands like â€œWhere is the door?â€ or â€œFind the chair,â€ and receive real-time verbal guidance based on AI-powered object recognition and direction awareness.

---

## âš™ï¸ Key Features

- ğŸ™ï¸ Natural voice command interface via Speech-to-Text (STT)
- ğŸ“· Real-time indoor object detection using YOLOv11n (TFLite)
- ğŸ”Š Audio navigation feedback using Text-to-Speech (pyttsx3)
- âš¡ Runs completely offline on Raspberry Pi 5
- ğŸ’ Compact, wearable, and power-efficient design
- ğŸ’¡ Directional logic: tells the user if the object is â€œin front,â€ â€œto your right,â€ etc how many steps away from you and the size of object.

---

## ğŸ§  Technologies Used

| Component           | Technology                     |
|--------------------|----------------------------------|
| Hardware           | Raspberry Pi 5, USB Webcam, AirPods |
| Object Detection   | YOLOv11n (custom & pre-trained) |
| Voice Recognition  | SpeechRecognition (Google STT) |
| Audio Feedback     |  pyttsx3 (Text-to-Speech)      |
| Programming        | Python 3                        |
| Vision Processing  | OpenCV                          |

---

## ğŸ›  Hardware Architecture

- **Raspberry Pi 5 (8GB)** â€“ main processor
- **USB Webcam** â€“ captures front-facing visual input
- **AirPods (Mic + Audio)** â€“ for voice command and feedback
- **Cooling Fan + Protective Case** â€“ ensures thermal stability
- **Portable Power Bank** â€“ for mobile, wearable operation

---

## ğŸ“ Project Structure

```bash
SightOfBlind/
â”œâ”€â”€ models/              # YOLOv11n TFLite models (float16 quantized)
â”œâ”€â”€ utils/               # Direction logic, preprocessing, helpers
â”œâ”€â”€ SightOfBlind.py      # Main script for system execution
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ media/               # Images, architecture diagrams, or demos
â””â”€â”€ README.md            # Project overview
```
---
## ğŸš€ Setup & Execution

1. Clone the Repository
```bash
git clone https://github.com/Obeidatt/SightOfBlind.git
cd SightOfBlind
```
2. Install Dependencies
```bash
pip install -r requirements.txt
```
3. Run the Application
```bash
python3 SightOfBlind.py
```
- âœ… Make sure Bluetooth is connected and Pi Camera is enabled.
  
## ğŸ“Š Performance Highlights

- âœ… **mAP@0.5**: 89.3%
- âœ… **Precision**: 90%
- âœ… **Recall**: 86%
- âœ… **FPS**: 8â€“12 on Raspberry Pi 5 (TFLite, float16)
- âœ… **Command-to-Feedback Time**: ~2 sec

Tested in classrooms, hallways, and dorm environments with high voice command accuracy and object recognition robustness.

## ğŸ”’ License

This repository is protected under intellectual property rights.

**All rights reserved Â© 2025 by the authors.**  
No part of this codebase may be copied, modified, distributed, or used in other projects without **explicit written permission**.

Contact: [@Obeidatt](https://github.com/Obeidatt) or Email: obeiidattt@gmail.com.

## ğŸ“¬ Contact

For access requests, academic inquiries, or demo opportunities:

**Anas Emad Falah Obeidat**  
ğŸ“§ Email: *obeiidattt@gmail.com*  
ğŸ”— GitHub: [github.com/Obeidatt](https://github.com/Obeidatt)

